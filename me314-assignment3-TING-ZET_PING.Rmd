
# ME314 Managing and Visualizing Data

```{r}
library(dplyr)
```
## Day 3 Assignment, LSE ME314 2018
---

```{r, include=FALSE, results='hide'}
txtCol = function(x, color){
  if(knitr::is_latex_output())
    paste("\\textcolor{",color,"}{",x,"}",sep="")
  else if(knitr::is_html_output())
    paste("<font color='",color,"'>",x,"</font>",sep="")
  else
    x
}
```



### 1.  Normalizing data

This question uses this table:
![Not normalized data](http://www.essentialsql.com/wp-content/uploads/2014/06/Intro-Table-Not-Normalized.png)

from the lecture notes.  For each answer, please explain as fully as possible, and feel free to use tables or diagrams if you prefer.


a)  Why does this table violate the first normal form, and what would be required to make it 1NF?
**Ans1**: Attributes Customer1:3 violate 1NF because these 3 form a group of attributes.

*Correction*: The rules to satisfy 1st normal form are:_
-  **That the data is in a database table.**
-  **The table stores information in rows and columns where one or more columns, called the primary key, uniquely identify each row.**
-  **Each column contains atomic values, and there are not repeating groups of columns.**}}


b)  What additional steps would be needed to make the table 2NF, and why?
**Ans_b : ** To make the table 2NF, we'll have to remove attributes OfficeNumber, Customer1, Customer2, Customer3

```{r echo=T, results='hide'}
# correction
print("Assuming that we have fixed the table into NF1, there are still issues. For example, as long as we know the name of sales office, we can know the sales office's phone number. This violates NF2 principles. ")
```

c)  Why might we not want to normalize data to the fullest extent possible?
**Ans_b : ** Reducing database to the fullest extent i.e. 7th Normal Form will often overly complicate simple retrieval and understanding of data. Casting all data into irreducible forms require more tables than is efficient for operations. 

```{r echo=T, results='hide'}
# correction
print("this is true for smaller databases. For large scale database scheme that need the ability to be extended easily, however, and for which data integrity is critical, full normalization is generally the best strategy.")
```

d)  In the table below, which of the three normalization rules does this violate, if any, and why?

   |  countryID  |  countryName    |   EUmember   |  EUjoindate  |
   | -----------:|:----------------|:------------:|:------------:|
   | 00001       | France          |  `true`      |  1958-01-01  |
   | 00004       | Hungary         |  `true`      |  2004-05-01  |
   | 00003       | Serbia          |  `false`     |       `NULL` |
   | 00004       | Finland         |  `true`      |  1995-01-01  |
   | 00005       | Russia          |  `false`     |       `NULL` |
   | 00006       | Ireland, UK     |  `true`      |  1973-01-01  |

   Are there any other problems with the table, besides normalization?


**Ans : ** This table is not in normal form 1. Attribute countryName violates NF1 because it contains non-atomic values such as 'Ireland, UK'. 
```{r echo=T, results='hide'}
# correction
print("2NF is violated because we could have created a table of EU membership statuses (including soon, sadly, un-joining) that would link to the Country table via `CountryID`.")
print("3NF is violates because the `EUmember` can be determined by whether the `EUjoindate` is not `NULL`.")
```

e)  What would it take to full (1NF-3NF) normalize this dataset?

   Write out these tables, and describe why this meets each of the normal forms.  This is a database of movies watched on NetBricks, a streaming movie service.

   | Name           | Address    |   Movies Rented   |  Salutation  | Category |
   |:---------------|:-----------|:------------------|:------------:|----------|
   | Bob Smith      | 1 Houghton Street    | _Star Wars_, _Inception_ |  Dr.   |  Scifi, Scifi |
   | Pry Ministair  | 10 Downing St     |  _Brexit the Movie_      |  Lady  | Tragedy |
   | Joe Bloggs     | 8 Myhatt St.      |  _Fast and Furious 6_, _Fast and Furious 7_     | Mr. | Action, Action |

**Ans: ** To get to NF1, one would have to melt the data on attributes Movies Rented, and then on Category. Once in NF1, NF2 is also satisfied. NF3 requires that Movies Rented and Category be removed. 

```{r}
# create user table
user_table <- read.csv(textConnection("userid, Name, Address, Salutation
                                      1, Bob Smith, 1 Houghton Street, Dr. 
                                      2, Pry Ministair, 10 Downing St, Lady
                                      3, Joe Bloggs, 8 Myhatt St., Mr."),           stringsAsFactors=FALSE)

# create Movies table
# do not add rented_by = c("Bob Smith", "Bob Smith", 
#                       "Pry Ministair", "Joe Bloggs", "Joe Blogss") here
movies_table <- data.frame(movieid = 1:5, 
                           movies = c("Star Wars", "Inception", 
                                      "Brexit the Movie", "Fast_ and Furious 6", 
                                      "Fast and Furious 7"), 
                           category_id = c(1, 1, 2, 3, 3))

# create rental table
rental_table <- data.frame(userid = c(1,1,2,3,3), 
                           movieid = 1:5)

# create category table 
category_table <- data.frame(category_id = 1:3,
                             category_name = c("Scifi", "Tragedy", "Action"), 
                             stringsAsFactors = FALSE)

```
### 2.  Reshaping data

For this exercise, we will use the **nycflights13** R package, whose tables have been output in `.csv` form [here](nycflights13/).  You may do the following in either R or Python.  Note that this example is developed extensively in [_R for Data Science_](http://r4ds.had.co.nz/relational-data.html).

a)  Create a subtable of the `flights` data, that departed before 05:53 on 2013-02-28.  How many rows and columns does this subtable have?  

```{r}

library("dplyr")
library("lubridate")

flights <- read.csv("nycflights13/flights.csv")

flights$dep_datetime <- ymd_hm(sprintf("%s-%02d-%02d %02d:%02d",
                            flights$year,
                            flights$month,
                            flights$day,
                            flights$hour,
                            flights$minute))
flights_sub <- subset(flights, dep_datetime < ymd_hm("2013-02-28 05:53"))

cat("number of row of `flights_sub is`", nrow(flights_sub))
cat("number of columns of `flights_sub` is", ncol(flights_sub))

```

```{r}

flights_sub <- flights %>% subset(year==2013 & # when use subset must sep conditions w `&`
                                  month==2 &
                                  day==28 &
                                  dep_time<553)

# or use dplyr filter
flights_sub2 <- flights %>% 
            dplyr::filter(year==2013 &  # when use dplyr::filter can sep with ","
                             month==2 & 
                             day==28 & 
                             dep_time<553)

# this creates an intermediatary column that we'll have to drop later. not ideal
flights_sub3 <- flights %>% 
            dplyr::mutate(., after_2013 = year >2013)

```

b)  Merge or join the subtable from a. `flights` data, to produce a result that includes: 
   *  Departure time
   *  Carrier (two digit code, from `carrier`)
   *  Flight number
   *  Destination airport name (hint: you will need to get this from the `airports` table)  
```{r}

airports <- read.csv("nycflights13/airports.csv")
mergedinfo <- flights %>% 
                  left_join(airports, c("dest" ="faa"))
# will produce warning  "Column `dest`/`faa` joining factors with different levels, coercing to character vector"
# but doesn't matter 

```

c) **(optional)** For every airline that had flights in the `flights` data compute the average age of the planes it flew from the entire dataset.  Age here will be defined as 2013 minus the `year` variable from the `planes` data.  Hint: This involves a join operation on `tailnum`, but also a grouped mean to compute the age (and subtracting 2013, which you can do before or after the computation of the mean).

```{r}
library(dplyr)
planes <- read.csv("nycflights13/planes.csv")

# below attempt failed. 
# flights %>% 
#   filtered(!duplicated(tailnum)) %>% 
#   inner_join(flights, by="tailnum") %>% 
#   mean(2013 - year) %>%
#   group_by(c("carrier"))
   

temp <- flights %>% 
   filter(!duplicated(tailnum)) %>%
   select(c("tailnum", "carrier")) %>% 
   left_join(planes, by="tailnum")

airlines <- read.csv("nycflights13/airlines.csv")

temp %>% 
   group_by(carrier) %>%
   summarise(mean_age = mean(2013 - year, na.rm=TRUE)) %>% 
   left_join(airlines, by="carrier") %>%
   select(c("name", "mean_age"))

temp %>% 
   group_by(carrier) %>%
   summarise(mean_age = mean(2013 - year, na.rm=TRUE))

# NT: try this thing using mutate 
temp %>%
   group_by(carrier) %>%
   dplyr::mutate(mean(2013-year, na.rm=TRUE)) %>% 
   select(c("mean(2013 - year, na.rm = TRUE)"))
```

### 3.  Working with SQL

a)  Create a relational dataset in SQLite using the `.csv` data found [here](nycflights13/).  Name each table so that it matches the base filenames of the input data.  You can use DB Browser for this, but describe how you did it, but the answer will use the R package [RSQLite](https://cran.r-project.org/web/packages/RSQLite/RSQLite.pdf). 
```{r}
library(RSQLite)

# first read the data
setwd("nycflights13/")
temp = list.files(pattern="*.csv")
# make names from all the csv files then assign read.csv to each. Write output to Global Environment
list2env(
  lapply(setNames(temp, make.names(gsub("*.csv$", "", temp))), 
         read.csv), envir = .GlobalEnv)

# then connect to db
library(DBI)
# Initialize a temporary in memory database and copy a data.frame into it
con <- dbConnect(RSQLite::SQLite(), ":memory:")

# create tables
# TODO use `mapply` for this!!!!
dbWriteTable(con, "airports", airports)
dbWriteTable(con, "airlines", airlines)
dbWriteTable(con, "flights", flights)
dbWriteTable(con, "planes", planes)
dbWriteTable(con, "weather", weather)
#sample: dbWriteTable(con, "USArrests", USArrests)
dbListTables(con)
setwd('..')
```

b)  Replicate B2 above using an SQL query, including both the command and the output.
```{r}
#   b)  Merge or join the subtable from a. `flights` data, to produce a result that includes:  
#   *  Departure time
#   *  Carrier (two digit code, from `carrier`)
#   *  Flight number
#   *  Destination airport name (hint: you will need to get this from the `airports` table)  

# can use dbSendQuery + dbFetch 
query <- dbSendQuery(con, statement = "SELECT dep_time, carrier, flight, name 
                                       from flights
                                       LEFT JOIN airports 
                                       on flights.dest = airports.faa ;")
 d1 <- dbFetch(query, n = 15)
 dim(d1)

 # or can use dbGetQuery
qoutput <- dbGetQuery(con, statement = "SELECT dep_time, carrier, flight, name 
                              from flights 
                              LEFT JOIN airports 
                              on flights.dest = airports.faa ;")

```

c) **(optional)** Replicate B3 above using an SQL query, including both the command and the output.
_c) **(optional)** For every airline that had flights in the `flights` data compute the average age of the planes it flew from the entire dataset.  Age here will be defined as 2013 minus the `year` variable from the `planes` data.  Hint: This involves a join operation on `tailnum`, but also a grouped mean to compute the age (and subtracting 2013, which you can do before or after the computation of the mean)._

```{r}
# remember to use SELECT DISTINCt for correct number
# I used AVG(2013-year) which is the same with 2013 - (AVG(planes.year)) apparently
tempsql <- dbGetQuery(con, "SELECT carrier, AVG(2013-year) AS avg_age FROM 
                  (SELECT DISTINCT tailnum, carrier FROM flights) AS fl
                   LEFT OUTER JOIN planes as pl ON fl.tailnum = pl.tailnum 
                  GROUP BY fl.carrier ")

tempsql
```


```{r}
dbDisconnect(con)
```


[ANSWER ENDS]